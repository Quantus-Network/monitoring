apiVersion: 1

groups:
  # Node Health Monitoring
  - orgId: 1
    name: Node Health Alerts
    folder: Alerts
    interval: 1m
    rules:
      # Alert when node is down
      - uid: node-down-alert
        title: Node Down
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              datasource:
                type: prometheus
                uid: prometheus
              expr: up{job=~".*-(substrate|node)"}
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
              instant: false
              range: true
          - refId: B
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              reducer: last
              refId: B
              type: reduce
          - refId: C
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              conditions:
                - evaluator:
                    params:
                      - 1
                    type: lt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: Alerting
        execErrState: Alerting
        for: 5m
        annotations:
          description: 'Node {{ index $labels "instance" }} (job: {{ index $labels "job" }}) is down for more than 5 minutes - check node status immediately'
          summary: 'Node {{ index $labels "instance" }} is DOWN'
        labels:
          severity: critical
        notification_settings:
          receiver: Email Notifications
      
      # Alert when peer count is low
      - uid: low-peer-count-alert
        title: Low Peer Count
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              datasource:
                type: prometheus
                uid: prometheus
              expr: substrate_sub_libp2p_peers_count{chain!="heisenberg"}
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
              instant: false
              range: true
          - refId: B
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              reducer: last
              refId: B
              type: reduce
          - refId: C
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              conditions:
                - evaluator:
                    params:
                      - 2
                    type: lt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 10m
        annotations:
          description: 'Node {{ index $labels "instance" }} (chain: {{ index $labels "chain" }}) has {{ printf "%.0f" $values.B.Value }} peers (threshold: <2) - check network connectivity'
          summary: 'Low peer count on {{ index $labels "instance" }}'
        labels:
          severity: warning
        notification_settings:
          receiver: Email Notifications
      # Alert when no new blocks for 3+ minutes
      - uid: no-new-blocks-alert
        title: No New Blocks
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: prometheus
            model:
              datasource:
                type: prometheus
                uid: prometheus
              expr: (time() - (qpow_metrics{data_group="last_block_time"} / 1000)) / 60
              refId: A
              instant: false
              range: true
          - refId: B
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              reducer: last
              refId: B
              type: reduce
          - refId: C
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              conditions:
                - evaluator:
                    params:
                      - 3
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: Alerting
        execErrState: Alerting
        for: 1m
        annotations:
          description: 'Chain {{ index $labels "chain" }} (instance: {{ index $labels "instance" }}) - last block was {{ printf "%.1f" $values.B.Value }} minutes ago (threshold: 3 minutes) - check block production'
          summary: 'No new blocks on {{ index $labels "chain" }}'
        labels:
          severity: critical
        notification_settings:
          receiver: Email Notifications

  # System Resource Monitoring
  - orgId: 1
    name: System Resource Alerts
    folder: Alerts
    interval: 2m
    rules:
      # Alert when CPU usage is high
      - uid: high-cpu-alert
        title: High CPU Usage
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              datasource:
                type: prometheus
                uid: prometheus
              expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
              instant: false
              range: true
          - refId: B
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              reducer: last
              refId: B
              type: reduce
          - refId: C
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              conditions:
                - evaluator:
                    params:
                      - 80
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 15m
        annotations:
          description: 'CPU usage on {{ index $labels "instance" }} has exceeded 80% (current: {{ printf "%.1f" $values.B.Value }}%) for more than 15 minutes'
          summary: 'High CPU usage on {{ index $labels "instance" }}'
        labels:
          severity: warning
        notification_settings:
          receiver: Email Notifications
      
      # Alert when memory usage is high
      - uid: high-memory-alert
        title: High Memory Usage
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              datasource:
                type: prometheus
                uid: prometheus
              expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
              instant: false
              range: true
          - refId: B
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              reducer: last
              refId: B
              type: reduce
          - refId: C
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              conditions:
                - evaluator:
                    params:
                      - 90
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 10m
        annotations:
          description: 'Memory usage on {{ index $labels "instance" }} has exceeded 90% (current: {{ printf "%.1f" $values.B.Value }}%) for more than 10 minutes'
          summary: 'High memory usage on {{ index $labels "instance" }}'
        labels:
          severity: warning
        notification_settings:
          receiver: Email Notifications
      
      # Alert when disk space is low
      - uid: low-disk-space-alert
        title: Low Disk Space
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              datasource:
                type: prometheus
                uid: prometheus
              expr: (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
              instant: false
              range: true
          - refId: B
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              reducer: last
              refId: B
              type: reduce
          - refId: C
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              conditions:
                - evaluator:
                    params:
                      - 85
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          description: 'Disk space on {{ index $labels "instance" }} has exceeded 85% usage (current: {{ printf "%.1f" $values.B.Value }}%) - immediate action required'
          summary: 'Low disk space on {{ index $labels "instance" }}'
        labels:
          severity: critical
        notification_settings:
          receiver: Email Notifications

  # Support Services Monitoring
  - orgId: 1
    name: Support Services Alerts
    folder: Alerts
    interval: 1m
    rules:
      # Alert when telemetry host is down
      - uid: telemetry-host-down-alert
        title: Telemetry Host Down
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              datasource:
                type: prometheus
                uid: prometheus
              expr: up{job="telemetry-host"}
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
              instant: false
              range: true
          - refId: B
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              expression: A
              reducer: last
              refId: B
              type: reduce
          - refId: C
            datasourceUid: __expr__
            model:
              datasource:
                type: __expr__
                uid: __expr__
              conditions:
                - evaluator:
                    params:
                      - 1
                    type: lt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: Alerting
        execErrState: Alerting
        for: 5m
        annotations:
          description: 'Telemetry Host ({{ index $labels "instance" }}) is down for more than 5 minutes - telemetry monitoring unavailable'
          summary: 'Telemetry Host is DOWN'
        labels:
          severity: critical
        notification_settings:
          receiver: Email Notifications
      
      # ===============================================
      # FAUCET MONITORING ALERTS (Dirac - Highest Priority)
      # ===============================================
      - uid: faucet_downtime
        title: Faucet Service Down
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: up{job="support-faucet"}
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0
                      - 0
                    type: gt
                  operator:
                    type: and
                  query:
                    params: []
                  reducer:
                    params: []
                    type: avg
                  type: query
              datasource:
                name: Expression
                type: __expr__
                uid: __expr__
              expression: A
              hide: false
              intervalMs: 1000
              maxDataPoints: 43200
              reducer: last
              refId: B
              type: reduce
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 1
                    type: lt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: Alerting
        execErrState: Alerting
        for: 2m
        annotations:
          description: 'Faucet service ({{ index $labels "instance" }}) is not responding - users cannot request tokens'
          summary: 'Faucet Service is DOWN'
        labels:
          chain: dirac
          severity: critical
        notification_settings:
          receiver: Email Notifications
      
      - uid: faucet_low_balance
        title: Faucet Low Balance
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: faucet_account_balance{job="support-faucet"} / 1e12
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0
                      - 0
                    type: gt
                  operator:
                    type: and
                  query:
                    params: []
                  reducer:
                    params: []
                    type: avg
                  type: query
              datasource:
                name: Expression
                type: __expr__
                uid: __expr__
              expression: A
              hide: false
              intervalMs: 1000
              maxDataPoints: 43200
              reducer: last
              refId: B
              type: reduce
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 100000
                    type: lt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: Alerting
        execErrState: Alerting
        for: 5m
        annotations:
          description: 'Faucet balance is {{ printf "%.0f" $values.B.Value }} QU (threshold: <100,000 QU) - please refill the account'
          summary: 'Faucet Balance is LOW'
        labels:
          chain: dirac
          severity: warning
        notification_settings:
          receiver: Email Notifications
      
      - uid: faucet_high_failure_rate
        title: Faucet High Transfer Failure Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: rate(faucet_failed_transfers{job="support-faucet"}[5m]) / (rate(faucet_total_requests{job="support-faucet"}[5m]) + 0.001)
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0
                      - 0
                    type: gt
                  operator:
                    type: and
                  query:
                    params: []
                  reducer:
                    params: []
                    type: avg
                  type: query
              datasource:
                name: Expression
                type: __expr__
                uid: __expr__
              expression: A
              hide: false
              intervalMs: 1000
              maxDataPoints: 43200
              reducer: last
              refId: B
              type: reduce
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0.2
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          description: 'Faucet transfer failure rate is {{ printf "%.1f" (mul $values.B.Value 100) }}% (threshold: >20%) - check logs and chain connection'
          summary: 'High Transfer Failure Rate'
        labels:
          chain: dirac
          severity: warning
        notification_settings:
          receiver: Email Notifications
      
      - uid: faucet_high_rejection_rate
        title: Faucet High Rejection Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: rate(faucet_rejected_requests{job="support-faucet"}[5m]) / (rate(faucet_total_requests{job="support-faucet"}[5m]) + 0.001)
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0
                      - 0
                    type: gt
                  operator:
                    type: and
                  query:
                    params: []
                  reducer:
                    params: []
                    type: avg
                  type: query
              datasource:
                name: Expression
                type: __expr__
                uid: __expr__
              expression: A
              hide: false
              intervalMs: 1000
              maxDataPoints: 43200
              reducer: last
              refId: B
              type: reduce
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              conditions:
                - evaluator:
                    params:
                      - 0.5
                    type: gt
                  operator:
                    type: and
                  query:
                    params:
                      - C
                  reducer:
                    params: []
                    type: last
                  type: query
              expression: B
              refId: C
              type: threshold
        noDataState: OK
        execErrState: Alerting
        for: 10m
        annotations:
          description: 'Faucet rejection rate is {{ printf "%.1f" (mul $values.B.Value 100) }}% (threshold: >50%) - possible spam or validation issues'
          summary: 'High Request Rejection Rate'
        labels:
          chain: dirac
          severity: warning
        notification_settings:
          receiver: Email Notifications
